"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[4406],{38933:a=>{a.exports=JSON.parse('{"tag":{"label":"generative ai","permalink":"/docs/tags/generative-ai","allTagsPath":"/docs/tags","count":6,"items":[{"id":"ai-lab/create-playground","title":"Creating a playground","description":"Creating a playground environment for a model.","permalink":"/docs/ai-lab/create-playground"},{"id":"ai-lab/download-model","title":"Downloading a model","description":"Downloading a model.","permalink":"/docs/ai-lab/download-model"},{"id":"ai-lab/installing","title":"Installing Podman AI Lab","description":"Podman AI Lab can help you run large language models (LLMs) locally with no pain.","permalink":"/docs/ai-lab/installing"},{"id":"ai-lab/index","title":"Podman AI Lab","description":"Podman AI Lab is an open source extension for Podman Desktop to work with LLMs.","permalink":"/docs/ai-lab/"},{"id":"ai-lab/start-recipe","title":"Starting a recipe","description":"Created a recipe also known as an inference server for interaction with a model.","permalink":"/docs/ai-lab/start-recipe"},{"id":"ai-lab/start-inference-server","title":"Starting an inference server","description":"Starting an inference server for a model.","permalink":"/docs/ai-lab/start-inference-server"}],"unlisted":false}}')}}]);